{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_mdl_nlp-train-sentiment.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "vHTvvc97SLj2",
        "kwKWWNdjSQio"
      ],
      "authorship_tag": "ABX9TyOJDQ6IMuOdWKT8WvqQ5NnX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jacKlinc/movie_review_sentiment/blob/main/notebooks/1_mdl_nlp_train_sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDXVfVjkIetU"
      },
      "source": [
        "!pip install -Uqq fastbook\n",
        "import fastbook"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JgcoNQEKArN"
      },
      "source": [
        "from fastbook import *"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yh9Ul2F7KMgH"
      },
      "source": [
        "# ImDB Movie Review Sentiment Analysis\n",
        "I want to predict whether a user's review is negative or postive based on the text they type. The idea behind this approach is to first use transfer learning with the Wikipedia model which has all its articles, this teaches the model how sentences are structured and what words come after what. The next step is to train on an imDB model, this introduces the model to words specific to film making, giving the model the domain specfic language to read reviews.\n",
        "\n",
        "---\n",
        "\n",
        "#### TODO\n",
        "- [ ] Tokenise words\n",
        "- [ ] Numericalise\n",
        "- [ ] Preprocess data\n",
        "- [ ] Train on imDB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pL9tvEPxMEM6"
      },
      "source": [
        "## Tokenisation\n",
        "This step converts a text corpus into something a computer can more easily understand. The main change is how punctuation and capital letters are handled, which seem pretty complicated to a computer. \n",
        "\n",
        "FastAI does not tokenise the words rather uses Spacy which is quite popular."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Maa6q5zbMpk7"
      },
      "source": [
        "Import imDB dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GV1P6afFMcU8"
      },
      "source": [
        "from fastai.text.all import *\n",
        "path = untar_data(URLs.IMDB)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvNfjP1hMzMV"
      },
      "source": [
        "files = get_text_files(path, folders=['train', 'test', 'unsup'])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PGvpauc-NCp-",
        "outputId": "f466d2f1-a5be-4e97-a637-e05d50af61bc"
      },
      "source": [
        "txt = files[0].open().read()\n",
        "txt[:60]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"I'm getting frustrated that so many people are complaining t\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHTvvc97SLj2"
      },
      "source": [
        "### Word Tokeniser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pn9rl-RzOPl2",
        "outputId": "6ce2939a-bdc9-49e2-e115-f17eeb6e5dfb"
      },
      "source": [
        "spacy = WordTokenizer()\n",
        "toks = first(spacy([txt]))\n",
        "print(coll_repr(toks, 30))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(#231) ['I',\"'m\",'getting','frustrated','that','so','many','people','are','complaining','that','this','show','is','propaganda','for','the','Christian','religion','.','I','watched','the','first','few','episodes','of','this','miniseries','and'...]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfnucYfEPAbi"
      },
      "source": [
        "The above step splits all words like \"it's\" into \"it\" and \"s\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIfVyCD-OvW_",
        "outputId": "753184f8-2255-401a-fef4-38936dd52bb6"
      },
      "source": [
        "tokeniser = Tokenizer(spacy)\n",
        "print(coll_repr(tokeniser(txt), 30))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(#254) ['xxbos','xxmaj','i',\"'m\",'getting','frustrated','that','so','many','people','are','complaining','that','this','show','is','propaganda','for','the','xxmaj','christian','religion','.','i','watched','the','first','few','episodes','of'...]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCihQDXdPK9F"
      },
      "source": [
        "This step adds special tokens for things like the beginning and end of sentences. Below are some examples:\n",
        "- `xxbos` is the beginning of a text stream\n",
        "- `xxmaj` is a capital letter\n",
        "\n",
        "\n",
        "Data is rarely clean and this also applies to the review data where things like HTML fragements and emtpy spaces are present. Luckily, FastAI provides some rules to help"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeSd_HWbPT3t",
        "outputId": "c2e84763-a6c3-4ad4-c3cc-6aad64d0f4f5"
      },
      "source": [
        "defaults.text_proc_rules"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<function fastai.text.core.fix_html>,\n",
              " <function fastai.text.core.replace_rep>,\n",
              " <function fastai.text.core.replace_wrep>,\n",
              " <function fastai.text.core.spec_add_spaces>,\n",
              " <function fastai.text.core.rm_useless_spaces>,\n",
              " <function fastai.text.core.replace_all_caps>,\n",
              " <function fastai.text.core.replace_maj>,\n",
              " <function fastai.text.core.lowercase>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "dKStnbwHRfbV",
        "outputId": "d8254995-df41-4503-f86f-3fd9c56d5f80"
      },
      "source": [
        "coll_repr(tokeniser('&amp'))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"(#2) ['xxbos','&']\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dATuS_d2RqeQ"
      },
      "source": [
        "`&amp` is unicode for `&` symbol, the tokeniser knows this and relaces the word with the correct one and prepends it with an `xxbos` token."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwKWWNdjSQio"
      },
      "source": [
        "### Sub-Word Tokeniser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OiXKgZYRpWP"
      },
      "source": [
        ""
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaEuz01_MLSC"
      },
      "source": [
        "## Numericalisation\n",
        "Maps the tokens created to indices in the text. The frequency of words is also counted, making it easier for the model to process a large number of repeated words. \n",
        "\n",
        "The sentence \"I like my dog and my cat\" would have \"I\" as `text[0]` and \"my\" as `text[2]` and `text[5]`; instead of storing this mapping twice, it would map \"my\" to both indices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpmJO_6ST8uc",
        "outputId": "1eae76ba-37f5-4976-ede4-1a42f1652dc1"
      },
      "source": [
        "toks = tokeniser(txt)\n",
        "print(coll_repr(tokeniser(txt), 31))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(#254) ['xxbos','xxmaj','i',\"'m\",'getting','frustrated','that','so','many','people','are','complaining','that','this','show','is','propaganda','for','the','xxmaj','christian','religion','.','i','watched','the','first','few','episodes','of','this'...]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6Z6FjPJUhMr"
      },
      "source": [
        "txts = L(o.open().read() for o in files[:2000])"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ma5bdQlWUTb6",
        "outputId": "9a31c6d2-7aac-429a-d616-7d93b930aa66"
      },
      "source": [
        "toks200 = txts[:200].map(tokeniser)\n",
        "toks200[0]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#254) ['xxbos','xxmaj','i',\"'m\",'getting','frustrated','that','so','many','people'...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "l2dSh-YLUuJN",
        "outputId": "36345d94-83b9-4d52-89eb-9a160e7f137a"
      },
      "source": [
        "num = Numericalize()\n",
        "num.setup(toks200)\n",
        "coll_repr(num.vocab, 20)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"(#1992) ['xxunk','xxpad','xxbos','xxeos','xxfld','xxrep','xxwrep','xxup','xxmaj','the',',','.','a','and','of','to','it','is','in','i'...]\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jc8_rtErVOiM",
        "outputId": "fb858e59-f248-47a4-fea0-29bd82476f1b"
      },
      "source": [
        "nums = num(toks)[:20]\n",
        "nums"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorText([   2,    8,   19,  142,  339,    0,   21,   47,  135,   83,   42,    0,   21,   20,  157,   17, 1465,   29,    9,    8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FJnaQJVWI5z"
      },
      "source": [
        "The numbers above represent the mappings from tokenised words to integers that the model can interpret. Next step is to put them into a model."
      ]
    }
  ]
}